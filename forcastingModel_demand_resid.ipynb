{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8eRZgHLfMoei"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch #pytorch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable \n",
    "import numpy as np\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "init_notebook_mode(connected='true')\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we test the performance of a second LSTM model different from the one with which we worked on the previous notebook. The preparation of the data is quite similar, for that reason we'll skip some steps in order to avoid repetition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ej1tOMfMoeq"
   },
   "source": [
    "# 3.2.1 Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "J4ZYxLrkMoer"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_location3</th>\n",
       "      <th>temp_location6</th>\n",
       "      <th>temp_location2</th>\n",
       "      <th>temp_location4</th>\n",
       "      <th>temp_location5</th>\n",
       "      <th>temp_location1</th>\n",
       "      <th>solar_location3</th>\n",
       "      <th>solar_location6</th>\n",
       "      <th>solar_location2</th>\n",
       "      <th>solar_location4</th>\n",
       "      <th>solar_location5</th>\n",
       "      <th>solar_location1</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>panel_temp_C</th>\n",
       "      <th>irradiance_Wm-2</th>\n",
       "      <th>pv_power_mw</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-03 00:00:00</th>\n",
       "      <td>7.460000</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>9.640000</td>\n",
       "      <td>6.680000</td>\n",
       "      <td>13.090000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03 00:30:00</th>\n",
       "      <td>7.282558</td>\n",
       "      <td>13.267767</td>\n",
       "      <td>9.672437</td>\n",
       "      <td>6.473844</td>\n",
       "      <td>13.150280</td>\n",
       "      <td>8.612679</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03 01:00:00</th>\n",
       "      <td>7.140000</td>\n",
       "      <td>13.320000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>6.270000</td>\n",
       "      <td>13.210000</td>\n",
       "      <td>8.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03 01:30:00</th>\n",
       "      <td>7.005434</td>\n",
       "      <td>13.341220</td>\n",
       "      <td>9.721495</td>\n",
       "      <td>6.082927</td>\n",
       "      <td>13.258410</td>\n",
       "      <td>8.720556</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>7.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03 02:00:00</th>\n",
       "      <td>6.860000</td>\n",
       "      <td>13.360000</td>\n",
       "      <td>9.730000</td>\n",
       "      <td>5.910000</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>8.740000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 21:00:00</th>\n",
       "      <td>6.570000</td>\n",
       "      <td>9.770000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>5.850000</td>\n",
       "      <td>9.660000</td>\n",
       "      <td>7.350000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 21:30:00</th>\n",
       "      <td>6.480775</td>\n",
       "      <td>9.521341</td>\n",
       "      <td>7.168624</td>\n",
       "      <td>5.629581</td>\n",
       "      <td>9.522279</td>\n",
       "      <td>7.294467</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 22:00:00</th>\n",
       "      <td>6.370000</td>\n",
       "      <td>9.410000</td>\n",
       "      <td>7.110000</td>\n",
       "      <td>5.540000</td>\n",
       "      <td>9.460000</td>\n",
       "      <td>7.230000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 22:30:00</th>\n",
       "      <td>6.186408</td>\n",
       "      <td>9.319553</td>\n",
       "      <td>6.980459</td>\n",
       "      <td>5.506806</td>\n",
       "      <td>9.399240</td>\n",
       "      <td>7.085178</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 23:00:00</th>\n",
       "      <td>5.930000</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>6.780000</td>\n",
       "      <td>5.530000</td>\n",
       "      <td>9.340000</td>\n",
       "      <td>6.860000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37535 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     temp_location3  temp_location6  temp_location2  \\\n",
       "datetime                                                              \n",
       "2017-11-03 00:00:00        7.460000       13.200000        9.640000   \n",
       "2017-11-03 00:30:00        7.282558       13.267767        9.672437   \n",
       "2017-11-03 01:00:00        7.140000       13.320000        9.710000   \n",
       "2017-11-03 01:30:00        7.005434       13.341220        9.721495   \n",
       "2017-11-03 02:00:00        6.860000       13.360000        9.730000   \n",
       "...                             ...             ...             ...   \n",
       "2019-12-24 21:00:00        6.570000        9.770000        7.300000   \n",
       "2019-12-24 21:30:00        6.480775        9.521341        7.168624   \n",
       "2019-12-24 22:00:00        6.370000        9.410000        7.110000   \n",
       "2019-12-24 22:30:00        6.186408        9.319553        6.980459   \n",
       "2019-12-24 23:00:00        5.930000        9.250000        6.780000   \n",
       "\n",
       "                     temp_location4  temp_location5  temp_location1  \\\n",
       "datetime                                                              \n",
       "2017-11-03 00:00:00        6.680000       13.090000        8.560000   \n",
       "2017-11-03 00:30:00        6.473844       13.150280        8.612679   \n",
       "2017-11-03 01:00:00        6.270000       13.210000        8.690000   \n",
       "2017-11-03 01:30:00        6.082927       13.258410        8.720556   \n",
       "2017-11-03 02:00:00        5.910000       13.300000        8.740000   \n",
       "...                             ...             ...             ...   \n",
       "2019-12-24 21:00:00        5.850000        9.660000        7.350000   \n",
       "2019-12-24 21:30:00        5.629581        9.522279        7.294467   \n",
       "2019-12-24 22:00:00        5.540000        9.460000        7.230000   \n",
       "2019-12-24 22:30:00        5.506806        9.399240        7.085178   \n",
       "2019-12-24 23:00:00        5.530000        9.340000        6.860000   \n",
       "\n",
       "                     solar_location3  solar_location6  solar_location2  \\\n",
       "datetime                                                                 \n",
       "2017-11-03 00:00:00         0.000000         0.000000         0.000000   \n",
       "2017-11-03 00:30:00        -0.000029        -0.000021        -0.000006   \n",
       "2017-11-03 01:00:00         0.000000         0.000000         0.000000   \n",
       "2017-11-03 01:30:00         0.000216         0.000166         0.000091   \n",
       "2017-11-03 02:00:00         0.000000         0.000000         0.000000   \n",
       "...                              ...              ...              ...   \n",
       "2019-12-24 21:00:00         0.000000         0.000000         0.000000   \n",
       "2019-12-24 21:30:00         0.000015         0.000143        -0.000012   \n",
       "2019-12-24 22:00:00         0.000000         0.000000         0.000000   \n",
       "2019-12-24 22:30:00        -0.000005        -0.000048         0.000004   \n",
       "2019-12-24 23:00:00         0.000000         0.000000         0.000000   \n",
       "\n",
       "                     solar_location4  solar_location5  solar_location1  month  \\\n",
       "datetime                                                                        \n",
       "2017-11-03 00:00:00         0.000000         0.000000         0.000000     11   \n",
       "2017-11-03 00:30:00        -0.000003        -0.000033        -0.000013     11   \n",
       "2017-11-03 01:00:00         0.000000         0.000000         0.000000     11   \n",
       "2017-11-03 01:30:00         0.000034         0.000242         0.000138     11   \n",
       "2017-11-03 02:00:00         0.000000         0.000000         0.000000     11   \n",
       "...                              ...              ...              ...    ...   \n",
       "2019-12-24 21:00:00         0.000000         0.000000         0.000000     12   \n",
       "2019-12-24 21:30:00         0.000149         0.000089        -0.000005     12   \n",
       "2019-12-24 22:00:00         0.000000         0.000000         0.000000     12   \n",
       "2019-12-24 22:30:00        -0.000050        -0.000030         0.000002     12   \n",
       "2019-12-24 23:00:00         0.000000         0.000000         0.000000     12   \n",
       "\n",
       "                     day  weekday  hour  minute  panel_temp_C  \\\n",
       "datetime                                                        \n",
       "2017-11-03 00:00:00    3        4     0       0          7.05   \n",
       "2017-11-03 00:30:00    3        5     0      30          7.38   \n",
       "2017-11-03 01:00:00    3        6     1       0          7.70   \n",
       "2017-11-03 01:30:00    3        7     1      30          7.48   \n",
       "2017-11-03 02:00:00    3        1     2       0          7.20   \n",
       "...                  ...      ...   ...     ...           ...   \n",
       "2019-12-24 21:00:00   24        7    21       0           NaN   \n",
       "2019-12-24 21:30:00   24        1    21      30           NaN   \n",
       "2019-12-24 22:00:00   24        2    22       0           NaN   \n",
       "2019-12-24 22:30:00   24        3    22      30           NaN   \n",
       "2019-12-24 23:00:00   24        4    23       0           NaN   \n",
       "\n",
       "                     irradiance_Wm-2  pv_power_mw  \n",
       "datetime                                           \n",
       "2017-11-03 00:00:00              0.0          0.0  \n",
       "2017-11-03 00:30:00              0.0          0.0  \n",
       "2017-11-03 01:00:00              0.0          0.0  \n",
       "2017-11-03 01:30:00              0.0          0.0  \n",
       "2017-11-03 02:00:00              0.0          0.0  \n",
       "...                              ...          ...  \n",
       "2019-12-24 21:00:00              NaN          NaN  \n",
       "2019-12-24 21:30:00              NaN          NaN  \n",
       "2019-12-24 22:00:00              NaN          NaN  \n",
       "2019-12-24 22:30:00              NaN          NaN  \n",
       "2019-12-24 23:00:00              NaN          NaN  \n",
       "\n",
       "[37535 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full = pd.read_csv('./Data/clean_task3/full_generation_set3.csv', parse_dates = True, index_col = 0)\n",
    "#elec = pd.DataFrame(full.pop('electricity'))\n",
    "#full = full.join(elec) \n",
    "full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddXWluvEMoeu"
   },
   "source": [
    "# 3.2.3 Data preprocesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lmm9wA3YMoev"
   },
   "source": [
    "Now we frame one more time the problem as a supervised learning problem adding columns for values for the previous hours and keeping the target columns as the current hour. The model will learn to predict the next 6 hours of energy consumption being given the previous N = 24 hours of meteorological data as well as previous electric load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DAawISAEMoew"
   },
   "outputs": [],
   "source": [
    " # convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    #df = pd.DataFrame(data)\n",
    "    df = data\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(data.shift(i))\n",
    "        names += [('{}(t-{})'.format(j, i)) for j in data.columns]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('{}(t)'.format(j)) for j in data.columns]\n",
    "        else:\n",
    "            names += [('{}(t+{})'.format(j, i)) for j in data.columns]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oFO59QZlc03c"
   },
   "outputs": [],
   "source": [
    "def weather_supervised(dataframe, n_in, n_out):\n",
    "    df = dataframe.copy()\n",
    "    df.pop('pv_power_mw')\n",
    "    return series_to_supervised(data = df, n_in = n_in, n_out = n_out, dropnan=True)\n",
    "\n",
    "def electric_supervised(dataframe, n_in, n_out):\n",
    "    elec = pd.DataFrame(dataframe['pv_power_mw'])\n",
    "    elec_sup = series_to_supervised(data = elec, n_in = n_in, n_out = n_out, dropnan=True)\n",
    "    return elec_sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oedH0l2vMoex"
   },
   "outputs": [],
   "source": [
    "electricity = electric_supervised(full, 24, 6)\n",
    "weather = weather_supervised(full, 24, 6)\n",
    "full = weather.iloc[:,:-6*9].join(electricity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "id": "OX7uvjJ5Moex",
    "outputId": "cd0de891-fb83-457f-c1af-93c3ec0c5115"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['temp_location3(t-24)', 'temp_location6(t-24)', 'temp_location2(t-24)',\n",
       "       'temp_location4(t-24)', 'temp_location5(t-24)', 'temp_location1(t-24)',\n",
       "       'solar_location3(t-24)', 'solar_location6(t-24)',\n",
       "       'solar_location2(t-24)', 'solar_location4(t-24)',\n",
       "       ...\n",
       "       'pv_power_mw(t-4)', 'pv_power_mw(t-3)', 'pv_power_mw(t-2)',\n",
       "       'pv_power_mw(t-1)', 'pv_power_mw(t)', 'pv_power_mw(t+1)',\n",
       "       'pv_power_mw(t+2)', 'pv_power_mw(t+3)', 'pv_power_mw(t+4)',\n",
       "       'pv_power_mw(t+5)'],\n",
       "      dtype='object', length=546)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fNBnGfiMoey"
   },
   "source": [
    "Separate data from labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7CgmHG_TMoey"
   },
   "outputs": [],
   "source": [
    "X = full.iloc[:,:-6]\n",
    "y = full.iloc[:,-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x26FlTkfMoez",
    "outputId": "76fdfd3a-8cdd-4e4c-e804-fbf8788a9865"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37171, 540), (37171, 6))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vAV-JMOMoez"
   },
   "source": [
    "Building scalers and normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nz-nNTExMoez"
   },
   "outputs": [],
   "source": [
    "mm = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "X_ss = ss.fit_transform(X)\n",
    "y_mm = mm.fit_transform(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZ2pSrGvMoe0"
   },
   "source": [
    "Spliting dataset into training, testing and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "b5pGoSCvMoe0"
   },
   "outputs": [],
   "source": [
    "#We split the data into 2/3 of the time for training and 1/3 for testing \n",
    "#which would lead to 2 years for training and one year fo testing\n",
    "train_hours = int(3*full.shape[0]/5)\n",
    "val_hours = int(full.shape[0]/5)\n",
    "test_hours = int(full.shape[0]/5)\n",
    "\n",
    "X_train = X_ss[:train_hours, :]\n",
    "X_val = X_ss[train_hours:val_hours, :]\n",
    "X_test = X_ss[train_hours + val_hours : , :]\n",
    "y_train = y_mm[:train_hours, :]\n",
    "y_val= y_mm[train_hours : val_hours, :]\n",
    "y_test = y_mm[train_hours + val_hours :, :]\n",
    "\n",
    "\n",
    "#to tensors and variables\n",
    "X_train_tensors = Variable(torch.Tensor(X_train))\n",
    "X_val_tensors = Variable(torch.Tensor(X_val))\n",
    "X_test_tensors = Variable(torch.Tensor(X_test))\n",
    "\n",
    "y_train_tensors = Variable(torch.Tensor(y_train))\n",
    "y_val_tensors = Variable(torch.Tensor(y_val))\n",
    "y_test_tensors = Variable(torch.Tensor(y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1wVM6YcMoe0"
   },
   "source": [
    "Reshaping input data with the sequential infromation (number of considered rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zldhluRiMoe0"
   },
   "outputs": [],
   "source": [
    "#reshaping to rows, timestamps, features\n",
    "seq = 1\n",
    "X_train_tensors_final = torch.reshape(X_train_tensors,   (int(X_train_tensors.shape[0]/seq), seq, X_train_tensors.shape[1]))\n",
    "X_test_tensors_final = torch.reshape(X_test_tensors,  (int(X_test_tensors.shape[0]/seq), seq, X_test_tensors.shape[1])) \n",
    "X_val_tensors_final = torch.reshape(X_val_tensors,  (int(X_val_tensors.shape[0]/seq), seq, X_val_tensors.shape[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mRY9cJ-WMoe0",
    "outputId": "775d7c18-2f1c-46ba-f331-2db0c3f378c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22302, 1, 540])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensors_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BclSaUqcMoe1"
   },
   "source": [
    "# 3.2.4 Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pg2YtJjaMoe1"
   },
   "outputs": [],
   "source": [
    "class LSTM_E_2(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length, num_dir, device):\n",
    "        super(LSTM_E_2, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes #number of outputs\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "        self.num_directions = num_dir\n",
    "\n",
    "        if num_dir == 2:\n",
    "            bi = True\n",
    "        else: \n",
    "            bi = False\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True, bidirectional = bi ) #lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size*num_dir, 300) #fully connected 1\n",
    "        self.fc = nn.Linear(300, num_classes) #fully connected last layer\n",
    "\n",
    "        self.relu = nn.ReLU() \n",
    "\n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.zeros(\n",
    "              self.num_layers*self.num_directions, x.size(0), self.hidden_size)).to(self.device) #hidden state\n",
    "        c_0 = Variable(torch.zeros(\n",
    "            self.num_layers*self.num_directions, x.size(0), self.hidden_size)).to(self.device) #internal state\n",
    "\n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        #print(output.shape)\n",
    "        out = output.view(-1, self.hidden_size*self.num_directions) #reshaping the data for Dense layer next\n",
    "        #print(out.shape)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc_1(out) #first Dense\n",
    "        out = self.relu(out) #relu\n",
    "        out = self.fc(out) #Final Output\n",
    "        #print(out.shape)\n",
    "        \n",
    "        return out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgzJpJy_Moe1"
   },
   "source": [
    "Create or load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "id": "pFCGcIDqVnmU",
    "outputId": "3f05998c-82f8-4343-dfe5-f10b4803e928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_E_2(\n",
      "  (lstm): LSTM(540, 133, batch_first=True)\n",
      "  (fc_1): Linear(in_features=133, out_features=300, bias=True)\n",
      "  (fc): Linear(in_features=300, out_features=6, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#checking if there are any saved model checkpoint\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "if os.path.isfile('./data/models/model_2_checkpoint.tar'):\n",
    "    #load the model\n",
    "    model = LSTM_E_2(num_classes = 6, input_size = X_train_tensors_final.shape[2], hidden_size=133, num_layers=1, seq_length=X_train_tensors_final.shape[1],  num_dir = 1, device=device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.to(device)\n",
    "    # Make sure to call input = input.to(device) on any input tensors that you feed to the model\n",
    "\n",
    "    checkpoint = torch.load('./data/models/model_2_checkpoint.tar', map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(model)\n",
    "    \n",
    "else:\n",
    "    model = LSTM_E_2(num_classes = 6, input_size = X_train_tensors_final.shape[2], hidden_size=133, num_layers=1, seq_length=X_train_tensors_final.shape[1],  num_dir = 1, device=device)\n",
    "    model.to(device)\n",
    "    print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Soo9hf3AMoe2"
   },
   "source": [
    "Determinig loss criterion, optimizer, num_epochs and learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rWZH8xyqMoe2"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001 #0.001 lr\n",
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "id": "SjvTtM_VPZpj",
    "outputId": "b5b261b5-a037-4010-d557-6e423d8ea697"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.07613, val_loss: 0.06572\n",
      "Epoch: 10, loss: 0.01860, val_loss: 0.01831\n",
      "Epoch: 20, loss: 0.01121, val_loss: 0.01186\n",
      "Epoch: 30, loss: 0.00805, val_loss: 0.00904\n"
     ]
    }
   ],
   "source": [
    "#train 1\n",
    "model.train()\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "X_test_tensors_final = X_test_tensors_final.to(device)\n",
    "y_test_tensors = y_test_tensors.to(device)\n",
    "X_train_tensors_final = X_train_tensors_final.to(device)\n",
    "y_train_tensors = y_train_tensors.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model.forward(X_train_tensors_final) #forward pass\n",
    "    optimizer.zero_grad() #calculate the gradient, manually setting to 0\n",
    "    # obtain the batch loss \n",
    "    loss = criterion(outputs, y_train_tensors)\n",
    "    train_loss.append(loss.item())\n",
    "    loss.backward() #calculates the loss of the loss function\n",
    "    optimizer.step() #improve from loss, i.e backpropagation\n",
    "\n",
    "    #validation\n",
    "    val_out = model.forward(X_test_tensors_final)\n",
    "    loss_val =criterion(val_out, y_test_tensors)\n",
    "    val_loss.append(loss_val.item())\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch: %d, loss: %1.5f, val_loss: %1.5f\" % (epoch, train_loss[epoch], val_loss[epoch])) \n",
    "\n",
    "epoch = np.arange(0,num_epochs)\n",
    "\n",
    "#plotting\n",
    "plt.plot(epoch, train_loss, label = \"Train loss\")\n",
    "plt.plot(epoch, val_loss, label = \"Validation loss\")\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSPTXR4QVWvM"
   },
   "outputs": [],
   "source": [
    "#to save model you'll have to train/keep training the model\n",
    "torch.save({\n",
    "            'epoch': len(epoch),\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss.item(),\n",
    "            }, './data/models/model_1_checkpoint.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRz4vXxlMoe3"
   },
   "source": [
    "# 3.2.5 Validating model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNKKpi0bMoe4"
   },
   "source": [
    "Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UB-ZFQBBMoe5"
   },
   "outputs": [],
   "source": [
    "df_X_ss = ss.transform(full.iloc[:,:-6]) #old transformers\n",
    "df_y_mm = mm.transform(full.iloc[:,-6:]) #old transformers\n",
    "df_X_ss = Variable(torch.Tensor(df_X_ss)) #converting to Tensors\n",
    "df_y_mm = Variable(torch.Tensor(df_y_mm))\n",
    "#reshaping the dataset\n",
    "df_X_ss = torch.reshape(df_X_ss, (df_X_ss.shape[0], 1, df_X_ss.shape[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "h3Ym_Y9FMoe5",
    "outputId": "fa34fbc1-29bb-441d-ebcd-43b71535f18b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "train_predict = model(df_X_ss.to(device))#forward pass\n",
    "data_predict = train_predict.cpu().data.numpy() #numpy conversion\n",
    "dataY_plot = df_y_mm.data.numpy()\n",
    "\n",
    "data_predict = mm.inverse_transform(data_predict) #reverse transformation\n",
    "dataY_plot = mm.inverse_transform(dataY_plot)\n",
    "\n",
    "plt.figure(figsize=(20,10)) #plotting\n",
    "plt.axvline(x=train_hours, c='r', linestyle='--') #size of the training set\n",
    "\n",
    "plt.plot(dataY_plot, label='Actuall Data') #actual plot\n",
    "plt.plot(data_predict, label='Predicted Data') #predicted plot\n",
    "plt.title('Time-Series Prediction')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(dataY_plot, data_predict ))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To the left of the dashed vertical line we have the training data and to the right the testing data. We see that the actual yearly trend seems to have been correctly fitted in the validation set. Here we have represented each of the 6 calculated values (for every hour avead) for each inout vector. \n",
    "\n",
    "We'll zoom in in the third year of the data set and compare the actual values vs. the forecasted ones to see how it fits monthly, weekly and daily fluctuations. \n",
    "We'll just use the first of te 6 calculated values based on the idea that the NN should learn the trend and fit a curve in those 30 points (24 before the current value, the current value, and 5 afterwards) being the fit closer to the actual value for the points that come earlier in the prediction curve. \n",
    "\n",
    "We see that the squared root of the MSE on the total data set is of 4.893, which is greater than in the previous model, but we should take into account that this model works not only one but six target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "-P8DLIb4UGVo",
    "outputId": "85aadd83-a039-43d0-b8d6-40f75f964823",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Predicted = go.Scatter(x=y[train_hours:].index, y=data_predict[train_hours:,0].flatten(), opacity = 1, name = 'Forecasted Value (1)', line=dict(color='violet'), yaxis='y')\n",
    "Actual = go.Scatter(x=y[train_hours:].index, y=y['electricity(t)'][train_hours:].values, opacity = 0.7, name = 'Actual Value', line=dict(color='royalBlue'), yaxis='y')\n",
    "layout = go.Layout(title='Electricity Forecasting', xaxis=dict(title='Hour'),\n",
    "                   yaxis=dict(title='kBTU', overlaying='y'),\n",
    "                  yaxis2=dict(title='kBTU', side='right'))\n",
    "fig = go.Figure(data=[Predicted, Actual], layout=layout)\n",
    "fig.show() # if this is rendered in colab, you should run fig.show(renderer='colab') instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first sight it seems that the model is not as good as the previous one at aproximating correctly the highest peaks of power load. However, there are some regions, namely between April and May, where the overestimation got reduced as well as the underestimation. At large scale, the overall performance of the twoo models seems to be similar. As the previous model, this one also captured the daily trends as well as the average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As thought, using the first forecasted hour to compare predicted and actual values, get a better fit of the patterns. In the following graph we see the fit using the last fitted value (the sixth hour ahead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Predicted = go.Scatter(x=y[train_hours:].index, y=data_predict[train_hours:,5].flatten(), opacity = 1, name = 'Forecasted Value (6)', line=dict(color='pink'), yaxis='y')\n",
    "Actual = go.Scatter(x=y[train_hours:].index, y=y['electricity(t)'][train_hours:].values, opacity = 0.7, name = 'Actual Value', line=dict(color='royalBlue'), yaxis='y')\n",
    "layout = go.Layout(title='Electricity Forecasting', xaxis=dict(title='Hour'),\n",
    "                   yaxis=dict(title='kBTU', overlaying='y'),\n",
    "                  yaxis2=dict(title='kBTU', side='right'))\n",
    "fig = go.Figure(data=[Predicted, Actual], layout=layout)\n",
    "fig.show() # if this is rendered in colab, you should run fig.show(renderer='colab') instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the previous model, this validation feeds the model always with the actual previous values (weather and electricity) without taking into account the forecasted value as part of the previous electricity load information. That would signify that this plot shows how the model performs strictly in the frame of the specified problem (forecast six hours ahead with 24 previous ACTUAL values). \n",
    "\n",
    "That being said, if we compare the two models with the task of predicting one hour ahead (the frame for the first model), the first model seems to outperform the second. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load forecast using predicted values as input values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3A_NcnxdnvLq"
   },
   "source": [
    "Once the model has been trained, we'll define a function to predict the energy consumption N hours ahead the last inputed data. \n",
    "We'd expect that the error of the forecast value sums up causing the forecast values to drift away from the actual values but in a smaller amount than in the previous model based on the arguments that were stated before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "raGCx5Tcn_G3",
    "outputId": "40b701ea-6517-4694-ad26-11b48f322f26"
   },
   "outputs": [],
   "source": [
    "full = pd.read_csv('./data/clean/full_data.csv', parse_dates = True, index_col = 0)\n",
    "elec = pd.DataFrame(full.pop('electricity'))\n",
    "full = full.join(elec) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGJtyAJzoOKc"
   },
   "outputs": [],
   "source": [
    "prev_fut = full.iloc[-1596:-1476,:] #amount of hours equivalent to 5 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mn5oJfuV54hX"
   },
   "outputs": [],
   "source": [
    "def daily_consumption_forecast_1(previous_df):\n",
    "    '''\n",
    "    Takes previous day weather and electrical load information and predicts next day load profile\n",
    "    '''\n",
    "    actual_val = pd.DataFrame(data = previous_df.values, columns = previous_df.columns, index = previous_df.index)\n",
    "    y_predic = []\n",
    "    for i in range(previous_df.shape[0]-30):\n",
    "        #filter out from data frame the 12+1 values which will be used\n",
    "        #to generate the input tensor. This includes the last predicted value.\n",
    "        previous = previous_df.iloc[i:i + 30,:]\n",
    "        #prepare and generate input array\n",
    "        electricity = electric_supervised(previous, 24, 6)\n",
    "        weather = weather_supervised(previous, 24, 6)\n",
    "        in_previous = weather.iloc[:,:-6*9].join(electricity)\n",
    "        # select inputs and targets\n",
    "        X_previous = in_previous.iloc[:,:-6]\n",
    "        y_previous = in_previous.iloc[:,-6:]\n",
    "        #normalization\n",
    "        X_val = ss.transform(X_previous)\n",
    "        y_val = mm.transform(y_previous) \n",
    "        #from array to tensors and variables\n",
    "        X_val_tensors = Variable(torch.Tensor(X_val))\n",
    "        y_val_tensors = Variable(torch.Tensor(y_val))\n",
    "        #reshape input tensor\n",
    "        seq = 1\n",
    "        X_val_tensors_final = torch.reshape(X_val_tensors,   (int(X_val_tensors.shape[0]/seq), seq, X_val_tensors.shape[1]))\n",
    "        #forward pass\n",
    "        model.eval()\n",
    "        y_pred = model.forward(X_val_tensors_final.to(device))\n",
    "        #reverse normalization\n",
    "        y_predict = y_pred.cpu().data.numpy() #numpy conversion\n",
    "        y_predict = mm.inverse_transform(y_predict)\n",
    "        #add to dataframe the calculated value for the next hour\n",
    "        aux = previous['electricity'].values.tolist()\n",
    "        aux[24] = y_predict.item(0) #we select only the first predicted value\n",
    "        y_predic.append(y_predict.item(0))\n",
    "        previous_df.iloc[i:i + 30,:]['electricity'] = aux\n",
    "\n",
    "    prediction = pd.DataFrame(data = previous_df.values, columns = previous_df.columns, index = previous_df.index)\n",
    "\n",
    "    return prediction, actual_val, y_predic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7hFAeHB44Hg"
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "pred,act, y_f = daily_consumption_forecast_1(prev_fut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "-d9HJd4e5L2X",
    "outputId": "a3e1dacb-6a10-4dfa-a355-60f01b00184c"
   },
   "outputs": [],
   "source": [
    "Predicted = go.Scatter(x=act.iloc[24:,:].index, y=np.array(y_f), opacity = 1, name = 'Forecasted Value', line=dict(color='orange'), yaxis='y')\n",
    "Actual = go.Scatter(x=act.index, y=act['electricity'].values, opacity = 0.7, name = 'Actual Value', line=dict(color='royalBlue'), yaxis='y')\n",
    "layout = go.Layout(title='Electricity Forecasting', xaxis=dict(title='Hour'),\n",
    "                   yaxis=dict(title='kBTU', overlaying='y'),\n",
    "                  yaxis2=dict(title='kBTU', side='right'))\n",
    "fig = go.Figure(data=[Predicted, Actual], layout=layout)\n",
    "fig.show() # if this is rendered in colab, you should run fig.show(renderer='colab') instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(act['electricity'].values[24:-6], np.array(y_f)))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qs5fadDwHbeg"
   },
   "source": [
    "We observe that the model tends to overestimate and underestimate in the first day (behaviour that we already observed). However, with the passing of the days, the forecasting outperforms the previous model in the way that the forcasted and actual curve stay closer with the passing of the days, fact that did not occur in the first model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graph below we show the equivalent graph of the first model.\n",
    "![1rst Model Performance](./data/images/model1_performance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next model we'll try a fully conected NN to compare the behaviour with this two LSTM-based models and see if with the framing with which we've been woking, LSTM make a substantial difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "model2_pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
